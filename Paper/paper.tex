\documentclass{llncs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{graphicx,color}
\usepackage{multicol}
\usepackage{bussproofs}
\usepackage{float}
\usepackage{centernot}
\usepackage{marginnote}

\usetikzlibrary{arrows,shapes,calc}

\DeclareFontFamily{U}{wncy}{}
\DeclareFontShape{U}{wncy}{m}{n}{<->wncyss10}{}
\DeclareSymbolFont{mcy}{U}{wncy}{m}{n}
\DeclareMathSymbol{\sh}{\mathord}{mcy}{"78} 
\DeclareMathOperator{\sha}{\sh}
\DeclareMathOperator{\tr}{Tr}
\DeclareMathOperator{\fin}{finite}
\DeclareMathOperator{\rely}{rely}
\DeclareMathOperator{\guar}{guar}
\DeclareMathOperator{\letters}{letters}
\DeclareMathOperator{\wlp}{wlp}
\DeclareMathOperator{\test}{test}
\DeclareMathOperator{\eval}{eval}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\edn}{end}

\newcommand{\udagger}{\text{$\rotatebox[origin=c]{180}{$\dagger$}$}}

\newtheorem{lem}{Lemma}

\begin{document}

\tikzstyle{elem} = [circle]
\tikzstyle{line} = [draw,thick, -latex']
\tikzstyle{rel} = [draw,thin,dashed, -latex']

\title{Algebraic Principles for Rely-Guarantee Style Concurrency Verification Tools}

\author{Alasdair Armstrong \and Victor B.~F.~Gomes \and Georg Struth}

\institute{Department of Computer Science, University of Sheffield, UK\\
\email{$\{$a.armstrong,v.gomes,g.struth$\}$@dcs.shef.ac.uk}}

\maketitle

\begin{abstract}
  We provide simple equational principles for deriving
  rely-guarantee-style inference rules and refinement laws based on
  idempotent semirings. We link the algebraic layer with concrete
  models of programs based on languages and execution traces. We have
  implemented the approach in Isabelle/HOL as a lightweight
  concurrency verification tool that supports reasoning about the
  control and data flow of concurrent programs with shared variables
  at different levels of abstraction. This is illustrated on two
  simple verification examples.
\end{abstract}

\pagestyle{plain}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

We aim to develop tools which support reasoning about concurrent
programs at varying levels of abstraction. At the highest level,
abstract algebra provides a framework for the prototyping of new
inference and refinement rules, whereas at the lowest level concrete
models of program stores allow for fine-grained reasoning about
program data flow. We have implemented this approach is the
Isabelle/HOL interactive theorem prover. Isabelle/HOL not only
provides us with a high degree of confidence in the correctness of our
theorems, but also supports the construction of custom proof tactics
and tools for program verification tasks. Our approach differs from
existing frameworks for rely-guarantee reasoning in
Isabelle~\cite{nieto}, both by making the link between concrete
programs and algebras explicit, but also by allowing arbitrary nested
parallelism.

For sequential programs the applicability of algebra, and Kleene
algebra in particular, has been known for over a decade. Kleene
algebra provides operations for non-deterministic choice, sequential
composition and finite iteration, in addition to skip and abort. With
appropriate extensions, Kleene algebras support Hoare-style program
verification, and allow the derivation of program equivalences and
refinement rules. Furthermore, Kleene algebra has been applied in many
applications, such as compiler
optimisation~\cite{kozen_certification_2000}, program construction,
transformation and termination analysis, and static analysis.

Algebra has also been applied in the study of separation logic, for
example, as the separation algebras in~\cite{ohearn}, or in algebraic
separation logic.

\fbox{Algebraic Separation Logic}

\fbox{Concurrent Kleene Algebra}

Rely-guarantee is a so called \emph{compositional} method, where the
verification of a large program is reduced the independent
verification of individual subprograms, with the interference from
other subprograms being abstractly captured by \emph{rely} and
\emph{guarantee} conditions. This form of compositionality is,
however, weaker than the strong notion of compositionality inherent in
algebra, where full congruence rules exist for every operator.

In this paper, we investigate algebraic principles for rely-guarantee
style reasoning. This has been explored previously, for example
in~\cite{cka}, but we extend this approach by considering a minimal
set of rules sufficient to derive the standard rely-guarantee
inference rules. Furthermore, we explore how the algebraic
compositionality of this approach can be broken in just the right way,
so as to capture the ideas of abstract interference conditions in
rely-guarantee reasoning.

The verification and construction of actual concurrent programs often
requires complex semantics involving synchronisation, termination
analysis and complicated data structures.

\fbox{We verify simple programs}

\fbox{Coherent framework for programs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algebraic Preliminaries}
\label{sec:KA}

\fbox{define weak trioid!}

Rely-guarantee algebras, which are introduced in the following
section, are based on dioids and Kleene algebras. A \emph{semiring} is
a structure $(S,+,\cdot,0,1)$ such that $(S,+,0)$ is a commutative
monoid, $(S,\cdot, 1)$ is a monoid and the distributivity laws $x\cdot
(y+z)=x\cdot z + y \cdot z$ and $(x+y)\cdot z = x\cdot z+y\cdot z$ as
well as the annihilation laws $x\cdot 0=0$ and $0\cdot x=0$ hold. A
\emph{dioid} is a semiring in which addition is idempotent:
$x+x=x$. Hence $(S,+,0)$ forms a join semilattice with least element
$0$ and partial order defined, as usual, as $x\le y\Leftrightarrow
x+y=y$. The operations of addition and multiplication are isotone with
respect to the order, that is, $x \le y $ implies $z+x\le z+y$,
$z\cdot x \le z\cdot y$ and $x\cdot z \le y\cdot z$. A dioid is
\emph{commutative} if multiplication is: $x\cdot y = y \cdot x$.

In the context of sequential programs, one typically thinks of $\cdot$
as sequential composition, $+$ as nondeterministic choice, $0$ as the
abortive action and $1$ as skip.  In this context it is essential that
multiplication is not commutative.  More formally, it is well known
that (regular) languages with language union as $+$ and language
product as $\cdot$, the empty language as $0$ and the empty word
language $\{\varepsilon\}$ as $1$ form dioids. Another model is formed
by binary relations with the union of relations as $+$, the product of
relations as $\cdot$, the empty relation as $0$ and the identity
relation as $1$. A model of commutative dioids is formed by sets of
(finite) multisets or Parikh vectors with multiset addition as
multiplication.

It is well known that commutative dioids can be used for modelling the
interaction between concurrent composition and nondeterministic
choice. The following definition serves as a basis for models of
concurrency in which sequential and concurrent composition
interact.\fbox{should we write $;$ instead of $\cdot$?} 

A \emph{trioid} is a structure $(S,+,\cdot,||,0,1)$ such that
$(S,+,\cdot,0,1)$ is a dioid and $(S,\cdot,||,0,1)$ a commutative
dioid. In a trioid there is no interaction between the sequential
composition $\cdot$ and the parallel composition $||$. On the one
hand, Gischer has shown that trioids are sound and complete for the
equational theory of series-parallel pomset languages~\cite{Gischer},
which form a well studied model of true concurrency. On the other
hand, he has also obtained a completeness result with respect to a
notion of pomset subsumption for trioids with the additional
\emph{interchange axiom} $(w \| x) \cdot (y \| z) \le (w \cdot y) \|
(x \cdot z)$ and it is well known that this additional axiom also
holds for (regular) languages in which $||$ is interpreted as the
shuffle or interleaving operation~\cite{Gischer}.

Formally, the \emph{shuffle} $\sha$ of two finite words is defined
inductively as
\begin{equation*}
\epsilon \sha s = \{s\}, \qquad s \sha \epsilon = \{s\},\qquad
as \sha bt = a(s \sha bt) \cup b(as \sha t),
\end{equation*}
which is then lifted to the shuffle product of languages $X$ and $Y$
as
\begin{equation*}
X \sha Y = \{x \sha y:\; x \in X \land x \in Y\}.
\end{equation*}
\fbox{I would use $||$ here}

For logics of programs, notions of iteration or recursion are
essential. A \emph{Kleene algebra} is a dioid expaned with a star
operation which satisfies the \emph{left unfold axiom} $1 + x\cdot
x^*\le x^*$ and the \emph{left} and \emph{right induction axiom} $z+x
\cdot y \le y\Rightarrow x^*\cdot z \le y$ and $z + y\cdot x \le y
z\cdot \Rightarrow x^* \le y$. It follows that $1+x\cdot x^* = x^*$
and that the right unfold axiom $1+x^*\cdot x=x^*$ is derivable as
well. Thus iteration $x^\ast$ is modelled as the least fixpoint of the
function $\lambda y. 1+x\cdot y$, which is the same as the least
fixpoint of $\lambda y.1+ y\cdot x$. A \emph{commutative Kleene
  algebra} is a Kleene algebra in which multiplication is commutative.

It is well known that (regular) languages form Kleene algebras and
that (regular) sets of multisets form commutative Kleene algebras. In
fact, Kleene algebras are complete with respect to the equational
theory of regular languages as well as the equational theory of binary
relations with the reflexive transitive closure operation as the
star~\cite{Kozen}. Moreover, commutative Kleene algebras are
complete with respect to the equational theory of regular languages
over multisets~\cite{Conway}. It follows that equations in
(commutative) Kleene algebras are decidable.

A \emph{bi-Kleene algebra} is a structure
$(K,+,\cdot,||,0,1,^*,^{(*)})$ such that $(K,+,\cdot,0,1,^*)$ is a
Kleene algebra and $(K,+,||,0,1,^{(*)})$ a commutative Kleene
algebra. Bi-Kleene algebras are sound and complete with respect to the
equational theory of regular series-parallel pomset languages, and the
equational theory is again decidable~\cite{LaurenceStruth}. A
\emph{concurrent Kleene algebra} is a bi-Kleene algebra which
satisfies the interchange law~\cite{Hoareetal}. It can be shown that
shuffle languages and regular series-parallel pomset languages with a
suitable notion of pomset subsumption form concurrent Kleene algebras.

In some contexts, it is also useful to add a meet operation $\sqcap$,
such that $(D,+,\sqcap)$ is a lattice. \fbox{expand}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Generalised Hoare Logics  in Kleene Algebra}

It is well known that the inference rules for sequential Hoare logic
(except the assignment axiom) can be derived in expansions of Kleene
algebras. One approach is as follows~\cite{MoellerStruth}. Suppose a
suitable Boolean algebra $B$ of \emph{tests} has been embedded into a
Kleene algebra $K$ such that $0$ and $1$ are the minimal and maximal
element of $B$, $+$ corresponds to join and $\cdot$ to
meet. Complements $-$ are defined only on $B$. Suppose further that a
\emph{backward diamond operator} $\langle x|p$ has been defined for
each $x\in K$ and $p\in B$, which models the set of all states to
which each terminating execution of program $x$ may lead from states
$q$. Finally suppose that a \emph{forward box operator} $|x]p$ has
been defined which models the (largest) set of states from which every
terminating execution of $x$ must end up in states $q$ and that boxes
and diamonds are adjoints of the Galois connection
\begin{equation*}
  \langle x|p \le q \Leftrightarrow p \le |x]q,
\end{equation*}
for all $x\in K$ and $p,q\in B$. It is then evident from the above
explanations that validity of a Hoare triple $\vdash \{p\}x\{q\}$ can
be encoded as $\langle x|p \le q$ and the weakest liberal precodition
operator $\mathsf{wlp}(x,q)$ as $|x]p$. Hence the relationship between
the proof theory and the semantics of Hoare logic is captured by the
Galois connection $ \vdash\{p\}x\{q\} \Leftrightarrow p \le
\mathsf{wlp}(x,q)$. It has been shown that the relational semantics of
sequential while-programs can be encoded in these \emph{modal Kleene
  algebras} and that the inference rules of Hoare logic can be
derived~\cite{MoellerStruth}.

In the context of concurrency, this relational approach is no longer
appropriate. Here, the following approach by
Tarlecki~\cite{tarlecki_language_1985} can be used instead. One can
now encode validity of a Hoare triple as
\begin{equation*}
  \vdash \{x\}y\{z\} \Leftrightarrow x \cdot y \le z
\end{equation*}
for arbitrary elements of a Kleene algebra $K$. Nevertheless all the
rules of sequential Hoare logic except the assignment axiom can still
be derived in this setting~\cite{Hoareetal}.  Tarlecki's motivating
explanations carry over to the algebraic approach. 

As an example we show the derivation of a generalised while
rule. Suppose $x\cdot t\cdot y\le x$. Then $x\cdot (t\cdot y)^\ast \le
x$ by the right induction axiom of Kleene algebra and therefore
$x\cdot (t\cdot y)^\ast t'\le x\cdot t'$ for arbitrary element $t'$ by
isotonicity of multiplication. This derives the while rule
\begin{equation*}
  \frac{\{x\cdot t\}y\{x\}}{\{x\}(t\cdot y)^\ast\{t'\cdot x\}}
\end{equation*}
for a generalised while loop $(t\cdot y)^\ast\cdot t'$, which
specialises to the conventional rule when $t$ and $t'$ are, in some
sense, complements.

The correspondence to a wlp-style semantics, as in model Kleene
algebra, now requires a generalisation of the Galois connection for
boxes and diamonds to multiplication and an upper adjoint in the form
of residuation.  This can be achieved in the context of \emph{action
  algebras}~\cite{pratt}, which expand Kleene algebras by operations
of left and right residuation defined by the Galois connections
\begin{equation*}
  xy\le z\Leftrightarrow x\le z\leftarrow y,\qquad xy\le z \Leftrightarrow y\le z\rightarrow x.
\end{equation*}
\fbox{please check that I didn't confuse these arrows} These
residuals, and now even the Kleene star can be axiomatised
equationally in action algebras. For a comprehensive list of the
properties of action algebras and their most important models
see~\cite{archive}, including the language and the relational
model. In analogy to the development in model Kleene algebra we can
now stipulate $ \wlp(x,y)=y\leftarrow x$ and obtain the Galois
connection
\begin{equation*}
  \vdash \{x\}y\{z\} \Leftrightarrow x\le \wlp(y,z)
\end{equation*}
with the characteristic properties $\vdash \{\wlp(y,z)\}y\{z\}$ and $x\le
\wlp(y,z)\Rightarrow \ \vdash \{x\}y\{z\}$. Moreover, if the action algebra is
also a quantale, and infinite sums exist, it follows that $
\wlp(y,z)=\sum\{x:\ \vdash \{x\}y\{z\}\}$.  It is obvious that this definition
makes sense in all models of action algebras and
quantales. Intuitively, suppose $p$ stands for the set of all
behaviours of a system, for instance the set of all execution traces,
that end in state $p$, and likewise for $q$. Then $\{p\}x\{q\}$ states
that all executions ending in $p$ can be extended by $x$ to executions
ending in $q$. $\wlp(x,q)$ is the most general behaviour, that is the
set of all executions $p$ after which all executions of $x$ must end
in $q$.

In the context of concurrent Kleene algebra, even without the parallel
star, additional inference rules can be derived, in particular 
\begin{equation*}
  \frac{\vdash\{x\}y\{z\}}{\vdash\{w||x\}y\{w||z\}}\qquad \frac{\vdash\{x_1\}y_1\{z_1\}\quad\vdash\{x_2\}y_2\{z_2\}}{\vdash\{x_1||x_2\}y_1||y_2\{z_1||z_2\}}
\end{equation*}
which correspond to the frame rule and the concurrency rule of
concurrent separation logic~\cite{} when $||$ is interpreted as
separating conjunction. In fact, the second inference rule is, in any
bi-Kleene algebra equivalent to the interchange axiom and the frame
rule is derivable from this axiom as well~\cite{Hoareetal}. The
precise connection between concurrent separation logic, a variant of
concurrent Kleene algebra and a resource transformer model has been
elaborated in~\cite{localitypaper}.

A residuation for concurrent composition can be considered as well:
\begin{equation*}
x\|y \le z \Leftrightarrow y \le x/z.
\end{equation*}
The residual $x/z$ represents the weakest program such that when
placed in parallel with $x$, the parallel composition behaves as $z$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A  Rely-Guarantee Algebra}
\label{sec:RG}

In this section we show how bi-Kleene algebras can be expanded into a
simple algebra that supports the derivation of rely-guarantee-style
inference rules. This development does \emph{not} use the interchange
law for several reasons. First, this law fails for fair parallel
composition $x\parallel_f y$ in a model with possibly infinite, or
non-terminating programs. In this model, $x \cdot y \not\leq
x \parallel_f y$ in the case whenever $x$ is non-terminating. Second,
it is not needed for deriving the usual concurrency laws. Third,
whereas it may be assumed in the models outlined in Section *** it
fails for the Aczel trace model in Section ***. \fbox{is that true?}

\fbox{this needs to be reworked. two letters for a set are not good}

\fbox{ the set RG doesn't need to be named in the algebra I think.}

\fbox{we can just start with a bi-KA and say that elements are relies/guarantees if they satisfy properties}

\fbox{what is a weak trioid?}

\fbox{say that we don't consider the parallel star}

\fbox{should we call relies and guarantees more generically
  ``conditions'' can call them $c$?}

A rely-guarantee algebra is a structure
$(K,RG,+,\sqcap,\cdot,\|,^\star,0,1)$, where $(K,+,\sqcap)$ is a
distributive lattice, $(K,+,\cdot,\|,0,1)$ is a weak trioid and
$(K,+,\cdot,^\star,0,1)$ is a Kleene algebra. $RG$ is a distinguished
subset of relys and guarantees which satisfy the following axioms
\begin{align}
r\|r &\le r, \label{rg1}\\
r &\le r\|r', \label{rg2}\\
r\|xy &= (r\|x)(r\|y), \label{rg3}\\
r\|x^+ &\le (r\|x)^+ \label{rg4}.
\end{align}
By convention, we use $r$ and $g$ to refer to elements of $RG$, and
$x,y,z$ for arbitrary elements of $K$. 

Axiom (\ref{rg1}) states that interference from a rely condition being
run twice in parallel is no different from just the interference from
that rely condition begin run once in parallel. Axiom (\ref{rg2})
states that interference from a single rely condition is less than
interference from itself and another rely condition. Axiom (\ref{rg3})
allows a rely or guarantee to be split across sequential
programs. Axiom (\ref{rg4}) is similar to Axiom (\ref{rg3}) in intent,
except it deals with finite iteration.

Some elementary consequences of these rules are as follows
\begin{align*}
1 &\le r,\\
r^\star = rr &= r = r\|r,\\
r\|x^+ &= (r\|x)^+.
\end{align*}

%% Could use better explanations.



Axioms (\ref{rg1}), (\ref{rg2}) and (\ref{rg3}) are independent. To
show this, we use Isabelle's
\emph{Nitpick}~\cite{blanchette_nitpick:_2010} counterexample generator
to construct models which violate each of these axioms, yet satisfy
all others. The models thus constructed for (\ref{rg1}) and
(\ref{rg3}) are shown in Figures \ref{fig:rg1} and \ref{fig:rg3}
respectively. The model constructed for (\ref{rg2}) is just the two
element rely-guarantee algebra with $0$ and $1$.

\begin{figure}[H]
\centering
\begin{minipage}{0.24\textwidth}
\begin{tikzpicture}[x=1.5cm,y=1.5cm,auto]
  \node (center) {};
  \node [elem] (r1) at (90:1) {$r_1$};
  \node [elem] (one) at (200:1) {$1$};
  \node [elem] (r2) at (20:1) {$r_2$};
  \node [elem] (zero) at (-90:1) {$0$};

  \path [line] (r1) -- (r2);
  \path [line] (r1) -- (one);
  \path [line] (r1) -- (zero);
  \path [line] (r2) -- (one);
  \path [line] (r2) -- (zero);
  \path [line] (one) -- (zero);
\end{tikzpicture}
\end{minipage}
\begin{minipage}{0.24\textwidth}
\begin{align*}
r_1 \| r_1 &= r_1\\
r_1 \| r_2 &= r_1\\
r_2 \| r_1 &= r_1\\
r_2 \| r_2 &= r_1
\end{align*}
\end{minipage}
\begin{minipage}{0.24\textwidth}
\begin{align*}
r_1r_1 &= r_1\\
r_1r_2 &= r_1\\
r_2r_1 &= r_1\\
r_2r_2 &= r_2
\end{align*}
\end{minipage}
\begin{minipage}{0.24\textwidth}
\begin{align*}
r_1^\star &= r_1\\
r_2^\star &= r_2
\end{align*}
\end{minipage}
\caption{4 element counterexample for $r \in RG \implies r\|r \le r$}
\label{fig:rg1}
\end{figure}

Axiom (\ref{rg4}) can be derived from (\ref{rg3}) in all finite
models. This is because any finite $K$ is complete, and in a complete
setting fixpoint laws can be used to show $r\|x^+ \le (r\|x)^+$. Thus
it is impossible to construct a finite model demonstrating that
(\ref{rg4}) is independent from (\ref{rg1}) -- (\ref{rg3}).

\begin{figure}[t]
\centering
\begin{minipage}{0.24\textwidth}
\begin{tikzpicture}[x=1.5cm,y=1.5cm,auto]
  \node (center) {};
  \node [elem] (r1) at (90:1) {$r_1$};
  \node [elem] (one) at (0:1) {$1$};
  \node [elem] (zero) at (-90:1) {$0$};

  \path [line] (r1) -- (one);
  \path [line] (r1) -- (zero);
  \path [line] (r1) -- (zero);
  \path [line] (one) -- (zero);
\end{tikzpicture}
\end{minipage}
\begin{minipage}{0.24\textwidth}
\begin{align*}
r_1 \| r_1 &= r_1\\
r_1 r_1 &= r_1\\
r_1^\star &= r_1
\end{align*}
\end{minipage}
\caption{3 element counterexample for $r \in RG \implies r\|xy = (r\|x)(r\|y)$}
\label{fig:rg3}
\end{figure}

Jones quintuples can be encodeded in this setting as
\begin{align}
r, g \vdash \{p\} c \{q\} \iff p(r\|c) \le q \land c \le g. \label{quin}
\end{align}
With this encoding we can derive the standard rely-guarantee inference
rules, as shown in Figure \ref{fig:rgrules}. Thus equations
(\ref{rg1}) to (\ref{rg4}), which are all necessary to derive these
rules, somehow represent a minimal set of axioms from which these
inference rules can be derived.

By using these residuals quintuples can be encoded in the following way,
which is equivalent to the encoding in Equation (\ref{quin}).
\begin{align}
r, g \vdash \{p\} c \{q\} \iff c \le r/(p \rightarrow q) \sqcap g \label{refine}.
\end{align}
This encoding allows us to think in terms of program refinement, as
$r/(p \rightarrow q) \sqcap g$ defines the weakest program that when
placed in parallel with interference from $r$, and guaranteeing
interference at most $g$, goes from $p$ to $q$---a generic
specification for a concurrent program.

\begin{figure}[tbh]
\centering
\begin{prooftree}
\RightLabel{Skip}
\AxiomC{$pr \le p$}
\UnaryInfC{$r, g \vdash \{p\}1\{p\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Weakening}
\AxiomC{$r' \le r$}
\AxiomC{$g \le g'$}
\AxiomC{$p \le p'$}
\AxiomC{$r', g' \vdash \{p'\}x\{q'\}$}
\AxiomC{$q' \le q$}
\QuinaryInfC{$r, g \vdash \{p\}x\{q\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Sequential}
\AxiomC{$r, g \vdash \{p\}x\{q\}$}
\AxiomC{$r, g \vdash \{q\}y\{s\}$}
\BinaryInfC{$r, g \vdash \{q\}xy\{s\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Parallel}
\AxiomC{$r_1, g_2 \vdash \{p_1\}x\{q_1\}$}
\AxiomC{$g_1 \le r_2$}
\AxiomC{$r_1, g_2 \vdash \{p_2\}y\{q_2\}$}
\AxiomC{$g_2 \le r_1$}
\QuaternaryInfC{$r_1 \sqcap r_2, g_1 \| g_2 \vdash \{p_1 \sqcap q_2\}x\|y\{q_1 \sqcap q_2\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Choice}
\AxiomC{$r, g \vdash \{p\}x\{q\}$}
\AxiomC{$r, g \vdash \{p\}y\{q\}$}
\BinaryInfC{$r, g \vdash \{p\}x + y\{q\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Star}
\AxiomC{$pr \le p$}
\AxiomC{$r, g \vdash \{p\}x\{p\}$}
\BinaryInfC{$r, g \vdash \{p\}x^\star\{p\}$}
\end{prooftree}
\caption{Rely-guarantee inference rules}
\label{fig:rgrules}
\end{figure}

% Or should this be weak?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Breaking Compositionality}
\label{sec:INT}

While the algebra in section \ref{sec:RG} is adequate for deriving the
standard inference rules, it's equality is too strong to capture many
interesting statements about concurrent programs. Consider the
congruence rule for parallel composition, which is inherent in the
algebraic approach:
\begin{align*}
x = y \implies x\|z = y\|z.
\end{align*}
This can be read as follows; if $x$ and $y$ are equal, then they must
be equal under all possible interference from any arbitrary $z$. At
first sight, this might seem to preclude any reasoning about
interference in a fine-grained way using purely algebra. This is not
the case, but breaking such inherent compositionality in just the
right way to capture interesting properties of concurrency requires
extra work.

The most obvious way we can acheive this is by expanding our
rely-guarantee algebra with an additional function $\pi$ and redefining
our quintuples as,
\begin{align*}
r, g \vdash \{p\} c \{q\} \iff \pi(p(r\|c)) \le \pi(q) \land c \le g.
\end{align*}
Since for any operator $\bullet$, it is not required that
\begin{align*}
\pi(x) = \pi(y) \implies \pi(x \bullet z) = \pi(y \bullet z),
\end{align*}
we can `break' compositionality in just the right way, provided we
choose the correct properties for $\pi$. For example, if we consider
the following seven axioms
\begin{align}
\pi(\pi(x)) &= \pi(x), \label{pi1}\\
x \le y \implies \pi(x) &\le \pi(y), \label{pi2}\\
\pi(x) &\le x, \label{pi3}\\
\pi(x^*) &\le \pi(\pi(x)^*), \label{pi4}\\
\pi(xy) &\le \pi(\pi(x)\pi(y)), \label{pi5}\\
\pi(x \sqcap y) &= \pi(x) \sqcap \pi(y). \label{pi6}
\end{align}

Axioms (\ref{pi1}) to (\ref{pi3}) show that $\pi$ is an interior
operator, while (\ref{pi4}) and (\ref{pi5}) allow us to introduce
$\pi$ as needed around sequential composition and finite iteration,
which allows us to substitute under those operators as required---we
only want to break compositionality for $\|$.

The above axioms indicate that we could define $\pi$ as a function
$\lambda x.\; x \sqcap c$ where $c$ satisfies
\begin{align}
x^* \sqcap c &\le (x \sqcap c)^* \sqcap c, \label{con1}\\
xy \sqcap c &\le (x \sqcap c)(y \sqcap c) \sqcap c. \label{con2}
\end{align}

As such we redefine our rely-guarantee algebra from section
\ref{sec:RG} as a structure $(K,RG,+,\sqcap,\cdot,\|,^\star,0,1,c)$
which, in addition to the rules in section \ref{sec:RG} satisfies both
(\ref{con1}) and (\ref{con2}).

All the rules in Figure \ref{fig:rgrules} can be derived with this
algebra, and moreover their proofs remain the same, mutatis
mutandis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Finite Language Model}
\label{sec:Model}

In this section, we construct a finite language model satisfying the
axioms in Section \ref{sec:RG}. Restricting our attention to finite
languages means we do not need to concern ourselves with non-algebraic
termination side-conditions, nor do we need to worry about additional
restrictions on parallel composition, e.g. fairness. However, all the
results in this section can easily be adapted to potentially
infinite languages, and our Isabelle/HOL formalisation includes these more
general definitions by using coinductively defined lazy lists to
represent words, and having a weakly-fair shuffle operator for such
infinite languages.

We consider languages where the alphabet contains state pairs of the
form $(\sigma_1,\sigma_2) \in \Sigma \times \Sigma$. A word in such a
language is \emph{consistent} if every such pair in a word has the
same first state as the previous transition's second state. For
example, $(\sigma_1,\sigma_2)(\sigma_2,\sigma_3)$ is consistent, while
$(\sigma_1,\sigma_2)(\sigma_3,\sigma_3)$ is inconsistent. Sets of
consistent words are essentially \emph{Aczel
  traces}~\cite{boer_formal_1999}, but lack the usual process
labels. We denote the set of all consistent words by $C$.

As usual, the product of two languages X and Y is defined as
\begin{align*}
XY = \{x\frown y.\; x \in X \land y \in Y\}.
\end{align*}
The language product is associative, and distributes over arbitrary
joins from both the left and the right, i.e.
\begin{align*}
X(\bigcup Y) = \bigcup\{XZ.\; Z \in Y\} \qquad \text{and} \qquad (\bigcup Y)X = \bigcup\{ZX.\; Z \in Y\}.
\end{align*}
The shuffle $\sha$ on a pair
of finite words is defined inductively as
\begin{align*}
\epsilon \sha s = \{s\}, \qquad s \sha \epsilon = \{s\},\\
as \sha bt = a(s \sha bt) \cup b(as \sha t),
\end{align*}
which is then lifted to languages X and Y as the shuffle product,
\begin{align*}
X \sha Y = \bigcup\{x \sha y.\; x \in X \land x \in Y\}.
\end{align*}
The shuffle product is associative, commutative, and distributes over
arbitrary joins. Both products share the same unit, $\{\epsilon\}$ and
zero, $\emptyset$. Proving properties of shuffle is suprisingly
tricky (especially if one considers infinite words). For a in-depth
treatment of the shuffle product see~\cite{shufflethings}. The
above properties are enough to show that $(\mathcal{P}((\Sigma\times\Sigma)^*),
\cup, \cdot,\sha, \emptyset, \{\epsilon\})$ forms a weak trioid.

The rely-guarantee elements in this model are sets containing all the
words which can be built from some set of state pairs in
$\Sigma\times\Sigma$. We define a function $\langle R\rangle$ which
lifts a relation $R$ to a language containing words of length one for
each pair in $R$. The set of rely-guaratee elements RG is then defined
as $\{r.\; \exists R. r = \langle R\rangle^*\}$. We can show that
$(\mathcal{P}((\Sigma\times\Sigma)^*), RG, \cup, \cdot,\sha,
\emptyset, \{\epsilon\}, C)$ is a rely-guarantee algebra.

Since $\langle R\rangle$ is atomic, it satisfies several useful properties, such as,
\begin{align*}
\langle R\rangle^\star \| \langle S\rangle &= \langle R\rangle^\star; \langle S\rangle; \langle R\rangle^\star\\
\langle R\rangle^\star \| \langle S\rangle^\star &= (\langle R\rangle^\star; \langle S\rangle^\star)^\star
\end{align*}

To demonstrate how this model works, consider the graphical
representation of a language shown below.

\begin{center}
\begin{tikzpicture}[x=1cm,auto]
  \node (center) {};
  \node [elem] (s12) {$\sigma_2$};
  \node [elem, above of=s12] (s11) {$\sigma_1$};
  \node [elem, below of=s12] (s13) {$\sigma_3$};
  \node [right of=s13, node distance=0.75cm] (r1) {};

  \node [elem, right of=s12, node distance=1.5cm] (s22) {$\sigma_2$};
  \node [elem, above of=s22] (s21) {$\sigma_1$};
  \node [elem, below of=s22] (s23) {$\sigma_3$};
  \node [right of=s23, node distance=0.75cm] (r2) {};

  \node [elem, right of=s22, node distance=1.5cm] (s32) {$\sigma_2$};
  \node [elem, above of=s32] (s31) {$\sigma_1$};
  \node [elem, below of=s32] (s33) {$\sigma_3$};
  \node [right of=s33, node distance=0.75cm] (r3) {};

  \node [elem, right of=s32, node distance=1.5cm] (s42) {$\sigma_2$};
  \node [elem, above of=s42] (s41) {$\sigma_1$};
  \node [elem, below of=s42] (s43) {$\sigma_3$};
  \node [right of=s43, node distance=0.75cm] (r4) {};


  \path [line] (s11) -- (s21);
  \path [line] (s21) -- (s32);
  \path [line] (s32) -- (s43);

  \path [rel] (s11) -- (s22);
  \path [rel] (s12) -- (s22);
  \path [rel] (s23) -- (s32);
\end{tikzpicture}
\end{center}
The language contains the following six words
\begin{align*}
(\sigma_1,\sigma_1)(\sigma_1,\sigma_2)(\sigma_2,\sigma_3), \qquad
(\sigma_1,\sigma_2)(\sigma_1,\sigma_2)(\sigma_2,\sigma_3),\\
(\sigma_2,\sigma_2)(\sigma_1,\sigma_2)(\sigma_2,\sigma_3), \qquad
(\sigma_1,\sigma_1)(\sigma_3,\sigma_2)(\sigma_2,\sigma_3),\\
(\sigma_1,\sigma_2)(\sigma_3,\sigma_2)(\sigma_2,\sigma_3), \qquad
(\sigma_2,\sigma_2)(\sigma_3,\sigma_2)(\sigma_2,\sigma_3),
\end{align*}
where only the first,
$(\sigma_1,\sigma_1)(\sigma_1,\sigma_2)(\sigma_2,\sigma_3)$ is
consistent. This word is highlighted with solid arrows in the
diagram above. Now if we shuffle the single state pair $(\sigma_2,
\sigma_3)$ into the above language, we might end up with a language as
below:

\begin{center}
\begin{tikzpicture}[x=1cm,auto]
  \node [elem] (s12) {$\sigma_2$};
  \node [elem, above of=s12] (s11) {$\sigma_1$};
  \node [elem, below of=s12] (s13) {$\sigma_3$};
  \node [right of=s13, node distance=0.75cm] (r1) {};

  \node [elem, right of=s12, node distance=1.5cm] (i2) {$\sigma_2$};
  \node [elem, above of=i2] (i1) {$\sigma_1$};
  \node [elem, below of=i2] (i3) {$\sigma_3$};
  \node [right of=i3, node distance=0.75cm] (ri) {};

  \node [elem, right of=i2, node distance=1.5cm] (s22) {$\sigma_2$};
  \node [elem, above of=s22] (s21) {$\sigma_1$};
  \node [elem, below of=s22] (s23) {$\sigma_3$};
  \node [right of=s23, node distance=0.75cm] (r2) {};

  \node [elem, right of=s22, node distance=1.5cm] (s32) {$\sigma_2$};
  \node [elem, above of=s32] (s31) {$\sigma_1$};
  \node [elem, below of=s32] (s33) {$\sigma_3$};
  \node [right of=s33, node distance=0.75cm] (r3) {};

  \node [elem, right of=s32, node distance=1.5cm] (s42) {$\sigma_2$};
  \node [elem, above of=s42] (s41) {$\sigma_1$};
  \node [elem, below of=s42] (s43) {$\sigma_3$};
  \node [right of=s43, node distance=0.75cm] (r4) {};


  \path [rel] (s11) -- (i1);
  \path [rel] (s21) -- (s32);
  \path [line] (s32) -- (s43);
  \path [line] (i2) -- (s23);

  \path [line] (s11) -- (i2);
  \path [line] (s12) -- (i2);
  \path [line] (s23) -- (s32);
\end{tikzpicture}
\end{center}

By performing this shuffle action, we no longer have a consistent word
from $\sigma_1$ to $\sigma_3$, but instead a consistent word from
$\sigma_2$ to $\sigma_3$ and $\sigma_1$ to $\sigma_3$. These new
consistent words were constructed from previously inconsistent
words---the shuffle operator can take two inconsistent words and
shuffle them together in such a way to generate many consistent
words. If we only considered consistent words, \'a la Aczel traces, we
would be unable to define such a shuffle operator directly on the
traces themselves, and would instead have to rely on some operational
semantics to generate traces.

Following~\cite{brookes_full_1993} and~\cite{dingel_refinement_2002},
we inductively generate the mumble language $w^\dagger$ for a word $w$
in a language over $\Sigma^2$ as follows: Assume $R,S,T \in \Sigma^2$
and $u,v,w \in (\Sigma^2)^*$. First, $w \in w^\dagger$. Secondly, if
$uRSv \in w^\dagger$ then $u(R;S)v \in w^\dagger$. This operation is
lifted to languages in the obvious way as
\begin{align*}
X^\dagger = \bigcup\{x^\dagger.\; x \in X\}.
\end{align*}
Stuttering is represented as a rely condition $\langle \Id\rangle^\star$
where $\Id$ is the identity relation. Two languages $X$ and $Y$ are
equal under stuttering if $\langle \Id\rangle^\star \| X =_\pi \langle
\Id\rangle^\star \| Y$.

Stuttering and mumbling are important for defining \emph{tests}. A
test is any language $P$ where $P \le \langle \Id\rangle$. We
write $\test(P)$ for $\langle \Id_P\rangle$. Without any
stuttering and mumbling the traces $\test(P); \test(Q)$ and
$\test(P \cap Q)$ are incomparable, as all words in the former have
length two, while all the words in the latter have length one. With mumbling we have that
\begin{align*}
\test(P \cap Q) \le_\pi \test(P); \test(Q)
\end{align*}
as the longer words in $\test(P);\test(Q)$ can be mumbled down into
the shorter words of $\test(P\cap Q)$, whereas with stuttering we
have the opposite,
\begin{align*}
\langle I\rangle^\star \| (\test(P);\test(Q)) \le_\pi \langle I\rangle^\star \| \test(P \cap Q).
\end{align*}
For the rest of the paper, we assume that all languages are
implicitly mumble closed.

Using tests, we can encoding common program statements such as if
statements and while loops as in Kozen's Kleene algebra with tests.
\begin{align*}
\text{if } P \text{ \{ } X \text { \} else \{ } Y \text{ \}} &= \test(P); X + \test(- P); Y\\
\text{while } P \text{ \{ } X \text{ \}} &= (\test(P);X)^\star;\test(- P)
\end{align*}
Finally, we define the operator $\edn(P)$ which is contains all the
words which end in a state satisfying $P$. Some useful properties of $\edn$ include
\begin{align*}
\edn(P); \test{Q} &\le_\pi \edn(P \cap Q),\\
\test(P) &\le \edn(Q),\\
\text{range}(\Id_P \circ R) \le P \implies \edn(P); \langle R\rangle^\star &\le_\pi \edn(P).
\end{align*}

In the trace model, assignment is defined as
\begin{align*}
  x := e = \bigcup v.\,\test\{\sigma.\,\eval(\sigma,e) = v\} \cdot x \leftarrow v
\end{align*}
where $x \leftarrow v$ denotes the atomic command which assigns the
value $v$ to $x$. The $\eval$ function evaluates an expression $e$ in
the state $\sigma$. Using this definition of assignment we can derive
the assignment rule
\begin{align*}
&\text{unchanged}(\text{vars}(e)) \cap \text{preserves}(P) \cap \text{preserves}(P[x/e]),\\
&\text{unchanged}(- {x})\\
&\vdash \{\edn(P)\} x := e \{\edn(P[x/e])\}.
\end{align*}

The rely condition states that the environment is not allowed to
modify any of the variables used when evaluating $e$, i.e. those
variables must remain unchanged, and also that the environment must
preserve the precondition and postcondition of the assignment
statement. In turn, the assignment statement itself guarantees that it
leaves every variable other than $x$ unchanged. Preserves and unchanged are defined as
\begin{align*}
\text{preserves}(P) &= \langle \{(\sigma,\sigma').\; P(\sigma) \implies P(\sigma')\}\rangle^\star,\\
\text{unchanged}(X) &= \langle \{(\sigma,\sigma').\; \forall v\in X.\; \sigma(v) = \sigma'(v)\}\rangle^\star.
\end{align*}
We also defined two futher rely conditions, increasing and decreasing,
which are defined much like unchanged except they only require that variables
increase or decrease, rather than stay the same.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Example}

Figure \ref{fig:findp} shows the classic FINDP program, which has been
used by numerous authors including Owicki~\cite{owicki},
Jones~\cite{jones}, de Roever~\cite{derover} and
Hayes~\cite{hayes}. The program finds the least element of an array
satisfying the predicate $P$. The index of the first element
satisfying $p$ is placed in the variable $f$. If there are no elements
of the array satisfying $P$ then $f$ will be set to the length of the
array. The program has two subprograms, $A$ and $B$, which run in
parallel, one of which searches the even indices while the other
searches the odd indices. A speedup over a sequential implementation
is acheived as $A$ will terminate when $B$ finds an element of the
array satisfying $P$ which is less than $i_A$.

\begin{figure}
\[
\begin{aligned}
&f_A := \text{len}(\text{array});\\
&f_B := \text{len}(\text{array});\\
&\left(
\begin{aligned}
&i_A = 0\\
&\text{while } i_A < f_A \land i_A < f_B \text{ \{ }\\
&\qquad\text{if } P(\text{array}[i_A]) \text{ \{}\\
&\qquad\qquad f_A := i_A\\
&\qquad\text{\} else \{}\\
&\qquad\qquad i_A := i_A + 2\\
&\qquad\text{\}}\\
&\text{\}}
\end{aligned}
\middle\|
\begin{aligned}
&i_B = 1\\
&\text{while } i_B < f_A \land i_B < f_B \text{ \{}\\
&\qquad\text{if } P(\text{array}[i_B]) \text{ \{}\\
&\qquad\qquad f_B := i_B\\
&\qquad\text{\} else \{}\\
&\qquad\qquad i_B := i_B + 2\\
&\qquad\text{\}}\\
&\text{\}}
\end{aligned}
\right);\\
&f = \text{min}(f_A,f_B)
\end{aligned}
\]
\caption{FINDP Program}
\label{fig:findp}
\end{figure}

To prove the correctness of FINDP, we must show that
\begin{align*}
\text{FINDP} \le_\pi \text{ends}\{\sigma.\; \text{leastp}(\sigma, f)\} + \text{ends}\{\sigma.\; \sigma(f) = \text{len}(\text{array})\}.
\end{align*}
where
\begin{align*}
\text{leastp}(\sigma, x) =  (\forall v<\sigma(x). \lnot P(\sigma(\text{array}[v])))\land P(\sigma(\text{array}[\sigma(x)])).
\end{align*}
The interesting part of this proof is the verification 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

CNPq EPSRC

\bibliography{paper}{}
\bibliographystyle{plain}

\end{document}
