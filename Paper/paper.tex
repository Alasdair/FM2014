\documentclass{llncs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{graphicx,color}
\usepackage{multicol}
\usepackage{bussproofs}
\usepackage{float}
\usepackage{centernot}
\usepackage{marginnote}

\usetikzlibrary{arrows,shapes,calc}

\DeclareFontFamily{U}{wncy}{}
\DeclareFontShape{U}{wncy}{m}{n}{<->wncyss10}{}
\DeclareSymbolFont{mcy}{U}{wncy}{m}{n}
\DeclareMathSymbol{\sh}{\mathord}{mcy}{"78} 
\DeclareMathOperator{\sha}{\sh}
\DeclareMathOperator{\tr}{Tr}
\DeclareMathOperator{\fin}{finite}
\DeclareMathOperator{\rely}{rely}
\DeclareMathOperator{\guar}{guar}
\DeclareMathOperator{\letters}{letters}
\DeclareMathOperator{\wlp}{wlp}
\DeclareMathOperator{\test}{test}
\DeclareMathOperator{\eval}{eval}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\edn}{end}

\newcommand{\udagger}{\text{$\rotatebox[origin=c]{180}{$\dagger$}$}}

\newtheorem{lem}{Lemma}

\begin{document}

\tikzstyle{elem} = [circle]
\tikzstyle{line} = [draw,thick, -latex']
\tikzstyle{rel} = [draw,thin,dashed, -latex']

\title{Algebraic Principles for Concurrency Verification Tools}

\author{Alasdair Armstrong \and Victor B.~F.~Gomes\thanks{Sponsored by CNPq, Brazil}  \and Georg Struth}

\institute{Department of Computer Science, University of Sheffield, UK\\
\email{$\{$a.armstrong,v.gomes,g.struth$\}$@dcs.shef.ac.uk}}

\maketitle

\begin{abstract}
  We investigate equational laws for the derivation of rely-guarantee
  style inference and refinement rules in the minimalistic setting of
  semirings. This algebraic level is linked with concrete programming
  models based on languages and execution traces. The approach has
  been implemented in Isabelle/HOL where the link between algebras and
  models supports reasoning about both the control and data flow of
  concurrent programs at varying levels of abstraction. Finally, we
  illustrate our approach via simple program verification examples.
\end{abstract}

\pagestyle{plain}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Semirings and Kleene Algebra}
\label{sec:KA}

A \emph{semiring} is an structure
$(D,+,\cdot,0,1)$ satisfying the following laws,
\begin{align*}
  x(y + z) &= xy + xz, &\qquad (x + y)z &= xz + yz,\\
  (x + y) + z &= x + (y + z), &\qquad (xy)z &= x(yz),\\
  x + y &= y + x, &\qquad 0 + x &= x,\\
  1x &= x, &\qquad x1 &= x,\\
  0x &= 0, &\qquad x0 &= 0.
\end{align*}
A semiring is \emph{idempotent} if $x + x = x$, and \emph{weak} if $x0
= 0$ does not hold. The natural partial order $\le$ is defined as $x
\le y $ iff $x + y = y$. In an idempotent semiring $(D,+,0)$ therefore
forms a join semilattice with least element $0$. Idempotent semirings
are also called \emph{dioids}. In some contexts, it is also useful to
add a meet operation $\sqcap$, such that $(D,+,\sqcap)$ is a lattice.

In the context of programs, one typically thinks of $\cdot$ as being
sequential composition, $+$ as non-deterministic choice, $0$ as the
abortive action and $1$ as skip. For concurrent software, it is
natural to extend the notion of a dioid to that of a \emph{trioid}
with operators for both sequential and parallel composition. Formally,
a trioid is a structure $(D,+,\cdot,\|,0,1)$ where $(D,+,\cdot,0,1)$
is a dioid and,
\begin{align*}
  x\|(y + z) &= x\|y + x\|z, &\qquad x\|y &= y\|x,\\
  (x\|y)\|z &= x\|(y\|z), &\qquad x\|1 &= x,\\
  0\|x &= x.
\end{align*}

In a trioid there are no laws governing the interaction between
sequential and parallel composition. One law which has been considered
in previous papers is the \emph{exchange} law~\cite{hoare_concurrent_2011,hoare_locality_2011}
\begin{align*}
  (w \| x) \cdot (y \| z) \le (w \cdot z) \| (x \cdot y).
\end{align*}

The exchange law is initially appealing as it provides a way to derive
many properties of parallel composition from a single law. For example
one can show that $\|$ must be commutative, or that $x\cdot y \le
x\|y$. However, there are many interesting models which do not satisfy
this law. First, one could consider fair parallel composition
$x\parallel_f y$ in a model with infinite, or non-terminating
programs. In this model, $x \cdot y \not\leq x \parallel_f y$ in the
case where $x$ is non-terminating. A second example would be
predicate-transformer style models for separation logic, where $\|$ is
interpreted as separating conjunction. In such models, $\|$ and
$\cdot$ have different units, which, in the presence of the exchange
law, implies that $\cdot$ is equal to $\|$.

A Kleene algebra~\cite{kozen_completeness_1994} expands a dioid with a star operation satisfying the laws
\begin{align*}
  1 + xx^* &\le x^*, &\qquad z + xy \le y &\implies x^*z \le y,\\
  1 + x^*x &\le x^*, &\qquad z + yx \le y &\implies zx^* \le y.
\end{align*}

For programs, the star represents finite iteration of a program $x$
zero or more times. For iteration where $x$ must be executed at least
once, we write $x^+$. One can similarly axiomatise a parallel star
operation.

A Kleene algebra expanded with a parallel composition operator such
that $(K,+,\cdot,\|,0,1)$ is a trioid in which the exchange law holds
is called a \emph{concurrent Kleene algebra}~\cite{hoare_concurrent_2011}.

In a (concurrent) Kleene algebra Hoare triples can be encoded \`a la
Tarlecki as $\{x\}y\{z\} \iff xy \le z$. Assume residuals axiomatised
by Galois connections
\begin{align*}
 x \le z \leftarrow y \iff xy \le z \iff y \le x \rightarrow z,
\end{align*}
exist, as in Pratt's \emph{action
  algebra}~\cite{pratt_action_1990}. Then the Hoare triple
$\{x\}y\{z\}$ is equivalent to $x \le z \leftarrow y$, where $z
\leftarrow y$ can be seen as $\wlp(y,z)$.

For sequential programs, Hoare logic can also be encoded algebraically by
expanding a Kleene algebra with a Boolean test subalgebra. A
\emph{Kleene algebra with tests} (KAT)~\cite{kozen_kleene_1997} is structure
$(K,B,+,\cdot,\phantom{|}^\star,\overline{\phantom{x}},0,1)$ where
$(K,+,\cdot,\phantom{|}^\star,0,1)$ is a Kleene algebra and
$(B,+,\cdot,\overline{\phantom{x}},0,1)$ is a Boolean algebra such
that $B \subseteq K$. The $\overline{\phantom{x}}$ operator is only
defined on elements of the Boolean subalgebra. We denote arbitrary
elements of $K$ by $x,y,z$ and tests by $p,q,r$.

In KAT Hoare triples are defined in the following (equivalent) ways
\begin{align*}
\{p\}x\{q\} \iff px \le xq \iff px = pxq \iff px\overline{q} = 0.
\end{align*}
Using these encodings all the rules of Hoare logic excluding the
assignment rule can be derived.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algebra for Rely-Guarantee}
\label{sec:RG}

A rely-guarantee algebra is a structure
$(K,RG,+,\sqcap,\cdot,\|,^\star,0,1)$, where $(K,+,\sqcap)$ is a
distributive lattice, $(K,+,\cdot,\|,0,1)$ is a weak trioid and
$(K,+,\cdot,^\star,0,1)$ is a Kleene algebra. $RG$ is a distinguished
subset of relys and guarantees which satisfy the following axioms
\begin{align}
r\|r &\le r, \label{rg1}\\
r &\le r\|r', \label{rg2}\\
r\|xy &= (r\|x)(r\|y), \label{rg3}\\
r\|x^+ &\le (r\|x)^+ \label{rg4}.
\end{align}
By convention, we use $r$ and $g$ to refer to elements of $RG$, and
$x,y,z$ for arbitrary elements of $K$. Some elementary consequences of these rules are as follows
\begin{align*}
1 &\le r,\\
r^\star = rr &= r = r\|r,\\
r\|x^+ &= (r\|x)^+.
\end{align*}

%% Could use better explanations.

Axiom (\ref{rg1}) states that interference from a rely condition being
run twice in parallel is no different from just the interference from
that rely condition begin run once in parallel. Axiom (\ref{rg2})
states that interference from a single rely condition is less than
interference from itself and another rely condition. Axiom (\ref{rg3})
allows a rely or guarantee to be split across sequential
programs. Axiom (\ref{rg4}) is similar to Axiom (\ref{rg3}) in intent,
except it deals with finite iteration.

Axioms (\ref{rg1}), (\ref{rg2}) and (\ref{rg3}) are independent. To
show this, we use Isabelle's
\emph{Nitpick}~\cite{blanchette_nitpick:_2010} counterexample generator
to construct models which violate each of these axioms, yet satisfy
all others. The models thus constructed for (\ref{rg1}) and
(\ref{rg3}) are shown in Figures \ref{fig:rg1} and \ref{fig:rg3}
respectively. The model constructed for (\ref{rg2}) is just the two
element rely-guarantee algebra with $0$ and $1$.

\begin{figure}[H]
\centering
\begin{minipage}{0.24\textwidth}
\begin{tikzpicture}[x=1.5cm,y=1.5cm,auto]
  \node (center) {};
  \node [elem] (r1) at (90:1) {$r_1$};
  \node [elem] (one) at (200:1) {$1$};
  \node [elem] (r2) at (20:1) {$r_2$};
  \node [elem] (zero) at (-90:1) {$0$};

  \path [line] (r1) -- (r2);
  \path [line] (r1) -- (one);
  \path [line] (r1) -- (zero);
  \path [line] (r2) -- (one);
  \path [line] (r2) -- (zero);
  \path [line] (one) -- (zero);
\end{tikzpicture}
\end{minipage}
\begin{minipage}{0.24\textwidth}
\begin{align*}
r_1 \| r_1 &= r_1\\
r_1 \| r_2 &= r_1\\
r_2 \| r_1 &= r_1\\
r_2 \| r_2 &= r_1
\end{align*}
\end{minipage}
\begin{minipage}{0.24\textwidth}
\begin{align*}
r_1r_1 &= r_1\\
r_1r_2 &= r_1\\
r_2r_1 &= r_1\\
r_2r_2 &= r_2
\end{align*}
\end{minipage}
\begin{minipage}{0.24\textwidth}
\begin{align*}
r_1^\star &= r_1\\
r_2^\star &= r_2
\end{align*}
\end{minipage}
\caption{4 element counterexample for $r \in RG \implies r\|r \le r$}
\label{fig:rg1}
\end{figure}

Axiom (\ref{rg4}) can be derived from (\ref{rg3}) in all finite
models. This is because any finite $K$ is complete, and in a complete
setting fixpoint laws can be used to show $r\|x^+ \le (r\|x)^+$. Thus
it is impossible to construct a finite model demonstrating that
(\ref{rg4}) is independent from (\ref{rg1}) -- (\ref{rg3}).

\begin{figure}[t]
\centering
\begin{minipage}{0.24\textwidth}
\begin{tikzpicture}[x=1.5cm,y=1.5cm,auto]
  \node (center) {};
  \node [elem] (r1) at (90:1) {$r_1$};
  \node [elem] (one) at (0:1) {$1$};
  \node [elem] (zero) at (-90:1) {$0$};

  \path [line] (r1) -- (one);
  \path [line] (r1) -- (zero);
  \path [line] (r1) -- (zero);
  \path [line] (one) -- (zero);
\end{tikzpicture}
\end{minipage}
\begin{minipage}{0.24\textwidth}
\begin{align*}
r_1 \| r_1 &= r_1\\
r_1 r_1 &= r_1\\
r_1^\star &= r_1
\end{align*}
\end{minipage}
\caption{3 element counterexample for $r \in RG \implies r\|xy = (r\|x)(r\|y)$}
\label{fig:rg3}
\end{figure}

Jones quintuples can be encodeded in this setting as
\begin{align}
r, g \vdash \{p\} c \{q\} \iff p(r\|c) \le q \land c \le g. \label{quin}
\end{align}
With this encoding we can derive the standard rely-guarantee inference
rules, as shown in Figure \ref{fig:rgrules}. Thus equations
(\ref{rg1}) to (\ref{rg4}), which are all necessary to derive these
rules, somehow represent a minimal set of axioms from which these
inference rules can be derived.

If we expand our rely-guarantee algebras to have residuals axiomatised
by Galois connections for both parallel and sequential composition,
i.e.
\begin{align}
xy \le z &\iff y \le x \rightarrow z, \label{res1}\\
xy \le z &\iff x \le z \leftarrow y, \label{res2}\\
x\|y \le z &\iff y \le x/z \label{res3},
\end{align}
then for sequential composition, (\ref{res1}) and (\ref{res2}) provide
a link between weakest-precondition style semantics and hoare
logic. As mentioned in Section \ref{sec:KA}, the triple $\{p\} c
\{q\}$ can be encoded as $pc \le q$, while $q \leftarrow c$ represents
$wlp(c,q)$. Equation (\ref{res2}) can thus be written as $\{p\} c
\{q\} \iff p \le wlp(c,q)$. The parallel residual $x/z$ can be
understood similarly as follows; it is the weakest program such that
when placed in parallel with $x$, the composition behaves as $z$.

By using these residuals quintuples can be encoded in the following way,
which is equivalent to the encoding in Equation (\ref{quin}).
\begin{align}
r, g \vdash \{p\} c \{q\} \iff c \le r/(p \rightarrow q) \sqcap g \label{refine}.
\end{align}
This encoding allows us to think in terms of program refinement, as
$r/(p \rightarrow q) \sqcap g$ defines the weakest program that when
placed in parallel with interference from $r$, and guaranteeing
interference at most $g$, goes from $p$ to $q$---a generic
specification for a concurrent program.

\begin{figure}[tbh]
\centering
\begin{prooftree}
\RightLabel{Skip}
\AxiomC{$pr \le p$}
\UnaryInfC{$r, g \vdash \{p\}1\{p\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Weakening}
\AxiomC{$r' \le r$}
\AxiomC{$g \le g'$}
\AxiomC{$p \le p'$}
\AxiomC{$r', g' \vdash \{p'\}x\{q'\}$}
\AxiomC{$q' \le q$}
\QuinaryInfC{$r, g \vdash \{p\}x\{q\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Sequential}
\AxiomC{$r, g \vdash \{p\}x\{q\}$}
\AxiomC{$r, g \vdash \{q\}y\{s\}$}
\BinaryInfC{$r, g \vdash \{q\}xy\{s\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Parallel}
\AxiomC{$r_1, g_2 \vdash \{p_1\}x\{q_1\}$}
\AxiomC{$g_1 \le r_2$}
\AxiomC{$r_1, g_2 \vdash \{p_2\}y\{q_2\}$}
\AxiomC{$g_2 \le r_1$}
\QuaternaryInfC{$r_1 \sqcap r_2, g_1 \| g_2 \vdash \{p_1 \sqcap q_2\}x\|y\{q_1 \sqcap q_2\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Choice}
\AxiomC{$r, g \vdash \{p\}x\{q\}$}
\AxiomC{$r, g \vdash \{p\}y\{q\}$}
\BinaryInfC{$r, g \vdash \{p\}x + y\{q\}$}
\end{prooftree}

\begin{prooftree}
\RightLabel{Star}
\AxiomC{$pr \le p$}
\AxiomC{$r, g \vdash \{p\}x\{p\}$}
\BinaryInfC{$r, g \vdash \{p\}x^\star\{p\}$}
\end{prooftree}
\caption{Rely-guarantee inference rules}
\label{fig:rgrules}
\end{figure}

% Or should this be weak?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Breaking Compositionality}
\label{sec:INT}

While the algebra in section \ref{sec:RG} is adequate for deriving the
standard inference rules, it's equality is too strong to capture many
interesting statements about concurrent programs. Consider the
congruence rule for parallel composition, which is inherent in the
algebraic approach:
\begin{align*}
x = y \implies x\|z = y\|z.
\end{align*}
This can be read as follows; if $x$ and $y$ are equal, then they must
be equal under all possible interference from any arbitrary $z$. At
first sight, this might seem to preclude any reasoning about
interference in a fine-grained way using purely algebra. This is not
the case, but breaking such inherent compositionality in just the
right way to capture interesting properties of concurrency requires
extra work.

The most obvious way we can acheive this is by expanding our
rely-guarantee algebra with an additional function $\pi$ and redefining
our quintuples as,
\begin{align*}
r, g \vdash \{p\} c \{q\} \iff \pi(p(r\|c)) \le \pi(q) \land c \le g.
\end{align*}
Since for any operator $\bullet$, it is not required that
\begin{align*}
\pi(x) = \pi(y) \implies \pi(x \bullet z) = \pi(y \bullet z),
\end{align*}
we can `break' compositionality in just the right way, provided we
choose the correct properties for $\pi$. For example, if we consider
the following seven axioms
\begin{align}
\pi(\pi(x)) &= \pi(x), \label{pi1}\\
x \le y \implies \pi(x) &\le \pi(y), \label{pi2}\\
\pi(x) &\le x, \label{pi3}\\
\pi(x^*) &\le \pi(\pi(x)^*), \label{pi4}\\
\pi(xy) &\le \pi(\pi(x)\pi(y)), \label{pi5}\\
\pi(x \sqcap y) &= \pi(x) \sqcap \pi(y). \label{pi6}
\end{align}

Axioms (\ref{pi1}) to (\ref{pi3}) show that $\pi$ is an interior
operator, while (\ref{pi4}) and (\ref{pi5}) allow us to introduce
$\pi$ as needed around sequential composition and finite iteration,
which allows us to substitute under those operators as required---we
only want to break compositionality for $\|$.

The above axioms indicate that we could define $\pi$ as a function
$\lambda x.\; x \sqcap c$ where $c$ satisfies
\begin{align}
x^* \sqcap c &\le (x \sqcap c)^* \sqcap c, \label{con1}\\
xy \sqcap c &\le (x \sqcap c)(y \sqcap c) \sqcap c. \label{con2}
\end{align}

As such we redefine our rely-guarantee algebra from section
\ref{sec:RG} as a structure $(K,RG,+,\sqcap,\cdot,\|,^\star,0,1,c)$
which, in addition to the rules in section \ref{sec:RG} satisfies both
(\ref{con1}) and (\ref{con2}).

All the rules in Figure \ref{fig:rgrules} can be derived with this
algebra, and moreover their proofs remain the same, mutatis
mutandis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Finite Language Model}
\label{sec:Model}

In this section, we construct a finite language model satisfying the
axioms in Section \ref{sec:RG}. Restricting our attention to finite
languages means we do not need to concern ourselves with non-algebraic
termination side-conditions, nor do we need to worry about additional
restrictions on parallel composition, e.g. fairness. However, all the
results in this section can easily be adapted to potentially
infinite languages, and our Isabelle/HOL formalisation includes these more
general definitions by using coinductively defined lazy lists to
represent words, and having a weakly-fair shuffle operator for such
infinite languages.

We consider languages where the alphabet contains state pairs of the
form $(\sigma_1,\sigma_2) \in \Sigma \times \Sigma$. A word in such a
language is \emph{consistent} if every such pair in a word has the
same first state as the previous transition's second state. For
example, $(\sigma_1,\sigma_2)(\sigma_2,\sigma_3)$ is consistent, while
$(\sigma_1,\sigma_2)(\sigma_3,\sigma_3)$ is inconsistent. Sets of
consistent words are essentially \emph{Aczel
  traces}~\cite{boer_formal_1999}, but lack the usual process
labels. We denote the set of all consistent words by $C$.

As usual, the product of two languages X and Y is defined as
\begin{align*}
XY = \{x\frown y.\; x \in X \land y \in Y\}.
\end{align*}
The language product is associative, and distributes over arbitrary
joins from both the left and the right, i.e.
\begin{align*}
X(\bigcup Y) = \bigcup\{XZ.\; Z \in Y\} \qquad \text{and} \qquad (\bigcup Y)X = \bigcup\{ZX.\; Z \in Y\}.
\end{align*}
The shuffle $\sha$ on a pair
of finite words is defined inductively as
\begin{align*}
\epsilon \sha s = \{s\}, \qquad s \sha \epsilon = \{s\},\\
as \sha bt = a(s \sha bt) \cup b(as \sha t),
\end{align*}
which is then lifted to languages X and Y as the shuffle product,
\begin{align*}
X \sha Y = \bigcup\{x \sha y.\; x \in X \land x \in Y\}.
\end{align*}
The shuffle product is associative, commutative, and distributes over
arbitrary joins. Both products share the same unit, $\{\epsilon\}$ and
zero, $\emptyset$. Proving properties of shuffle is suprisingly
tricky (especially if one considers infinite words). For a in-depth
treatment of the shuffle product see~\cite{shufflethings}. The
above properties are enough to show that $(\mathcal{P}((\Sigma\times\Sigma)^*),
\cup, \cdot,\sha, \emptyset, \{\epsilon\})$ forms a weak trioid.

The rely-guarantee elements in this model are sets containing all the
words which can be built from some set of state pairs in
$\Sigma\times\Sigma$. We define a function $\langle R\rangle$ which
lifts a relation $R$ to a language containing words of length one for
each pair in $R$. The set of rely-guaratee elements RG is then defined
as $\{r.\; \exists R. r = \langle R\rangle^*\}$. We can show that
$(\mathcal{P}((\Sigma\times\Sigma)^*), RG, \cup, \cdot,\sha,
\emptyset, \{\epsilon\}, C)$ is a rely-guarantee algebra.

Since $\langle R\rangle$ is atomic, it satisfies several useful properties, such as,
\begin{align*}
\langle R\rangle^\star \| \langle S\rangle &= \langle R\rangle^\star; \langle S\rangle; \langle R\rangle^\star\\
\langle R\rangle^\star \| \langle S\rangle^\star &= (\langle R\rangle^\star; \langle S\rangle^\star)^\star
\end{align*}

To demonstrate how this model works, consider the graphical
representation of a language shown below.

\begin{center}
\begin{tikzpicture}[x=1cm,auto]
  \node (center) {};
  \node [elem] (s12) {$\sigma_2$};
  \node [elem, above of=s12] (s11) {$\sigma_1$};
  \node [elem, below of=s12] (s13) {$\sigma_3$};
  \node [right of=s13, node distance=0.75cm] (r1) {};

  \node [elem, right of=s12, node distance=1.5cm] (s22) {$\sigma_2$};
  \node [elem, above of=s22] (s21) {$\sigma_1$};
  \node [elem, below of=s22] (s23) {$\sigma_3$};
  \node [right of=s23, node distance=0.75cm] (r2) {};

  \node [elem, right of=s22, node distance=1.5cm] (s32) {$\sigma_2$};
  \node [elem, above of=s32] (s31) {$\sigma_1$};
  \node [elem, below of=s32] (s33) {$\sigma_3$};
  \node [right of=s33, node distance=0.75cm] (r3) {};

  \node [elem, right of=s32, node distance=1.5cm] (s42) {$\sigma_2$};
  \node [elem, above of=s42] (s41) {$\sigma_1$};
  \node [elem, below of=s42] (s43) {$\sigma_3$};
  \node [right of=s43, node distance=0.75cm] (r4) {};


  \path [line] (s11) -- (s21);
  \path [line] (s21) -- (s32);
  \path [line] (s32) -- (s43);

  \path [rel] (s11) -- (s22);
  \path [rel] (s12) -- (s22);
  \path [rel] (s23) -- (s32);
\end{tikzpicture}
\end{center}
The language contains the following six words
\begin{align*}
(\sigma_1,\sigma_1)(\sigma_1,\sigma_2)(\sigma_2,\sigma_3), \qquad
(\sigma_1,\sigma_2)(\sigma_1,\sigma_2)(\sigma_2,\sigma_3),\\
(\sigma_2,\sigma_2)(\sigma_1,\sigma_2)(\sigma_2,\sigma_3), \qquad
(\sigma_1,\sigma_1)(\sigma_3,\sigma_2)(\sigma_2,\sigma_3),\\
(\sigma_1,\sigma_2)(\sigma_3,\sigma_2)(\sigma_2,\sigma_3), \qquad
(\sigma_2,\sigma_2)(\sigma_3,\sigma_2)(\sigma_2,\sigma_3),
\end{align*}
where only the first,
$(\sigma_1,\sigma_1)(\sigma_1,\sigma_2)(\sigma_2,\sigma_3)$ is
consistent. This word is highlighted with solid arrows in the
diagram above. Now if we shuffle the single state pair $(\sigma_2,
\sigma_3)$ into the above language, we might end up with a language as
below:

\begin{center}
\begin{tikzpicture}[x=1cm,auto]
  \node [elem] (s12) {$\sigma_2$};
  \node [elem, above of=s12] (s11) {$\sigma_1$};
  \node [elem, below of=s12] (s13) {$\sigma_3$};
  \node [right of=s13, node distance=0.75cm] (r1) {};

  \node [elem, right of=s12, node distance=1.5cm] (i2) {$\sigma_2$};
  \node [elem, above of=i2] (i1) {$\sigma_1$};
  \node [elem, below of=i2] (i3) {$\sigma_3$};
  \node [right of=i3, node distance=0.75cm] (ri) {};

  \node [elem, right of=i2, node distance=1.5cm] (s22) {$\sigma_2$};
  \node [elem, above of=s22] (s21) {$\sigma_1$};
  \node [elem, below of=s22] (s23) {$\sigma_3$};
  \node [right of=s23, node distance=0.75cm] (r2) {};

  \node [elem, right of=s22, node distance=1.5cm] (s32) {$\sigma_2$};
  \node [elem, above of=s32] (s31) {$\sigma_1$};
  \node [elem, below of=s32] (s33) {$\sigma_3$};
  \node [right of=s33, node distance=0.75cm] (r3) {};

  \node [elem, right of=s32, node distance=1.5cm] (s42) {$\sigma_2$};
  \node [elem, above of=s42] (s41) {$\sigma_1$};
  \node [elem, below of=s42] (s43) {$\sigma_3$};
  \node [right of=s43, node distance=0.75cm] (r4) {};


  \path [rel] (s11) -- (i1);
  \path [rel] (s21) -- (s32);
  \path [line] (s32) -- (s43);
  \path [line] (i2) -- (s23);

  \path [line] (s11) -- (i2);
  \path [line] (s12) -- (i2);
  \path [line] (s23) -- (s32);
\end{tikzpicture}
\end{center}

By performing this shuffle action, we no longer have a consistent word
from $\sigma_1$ to $\sigma_3$, but instead a consistent word from
$\sigma_2$ to $\sigma_3$ and $\sigma_1$ to $\sigma_3$. These new
consistent words were constructed from previously inconsistent
words---the shuffle operator can take two inconsistent words and
shuffle them together in such a way to generate many consistent
words. If we only considered consistent words, \'a la Aczel traces, we
would be unable to define such a shuffle operator directly on the
traces themselves, and would instead have to rely on some operational
semantics to generate traces.

Following~\cite{brookes_full_1993} and~\cite{dingel_refinement_2002},
we inductively generate the mumble language $w^\dagger$ for a word $w$
in a language over $\Sigma^2$ as follows: Assume $R,S,T \in \Sigma^2$
and $u,v,w \in (\Sigma^2)^*$. First, $w \in w^\dagger$. Secondly, if
$uRSv \in w^\dagger$ then $u(R;S)v \in w^\dagger$. This operation is
lifted to languages in the obvious way as
\begin{align*}
X^\dagger = \bigcup\{x^\dagger.\; x \in X\}.
\end{align*}
Stuttering is represented as a rely condition $\langle \Id\rangle^\star$
where $\Id$ is the identity relation. Two languages $X$ and $Y$ are
equal under stuttering if $\langle \Id\rangle^\star \| X =_\pi \langle
\Id\rangle^\star \| Y$.

Stuttering and mumbling are important for defining \emph{tests}. A
test is any language $P$ where $P \le \langle \Id\rangle$. We
write $\test(P)$ for $\langle \Id_P\rangle$. Without any
stuttering and mumbling the traces $\test(P); \test(Q)$ and
$\test(P \cap Q)$ are incomparable, as all words in the former have
length two, while all the words in the latter have length one. With mumbling we have that
\begin{align*}
\test(P \cap Q) \le_\pi \test(P); \test(Q)
\end{align*}
as the longer words in $\test(P);\test(Q)$ can be mumbled down into
the shorter words of $\test(P\cap Q)$, whereas with stuttering we
have the opposite,
\begin{align*}
\langle I\rangle^\star \| (\test(P);\test(Q)) \le_\pi \langle I\rangle^\star \| \test(P \cap Q).
\end{align*}
For the rest of the paper, we assume that all languages are
implicitly mumble closed.

Using tests, we can encoding common program statements such as if
statements and while loops as in Kozen's Kleene algebra with tests.
\begin{align*}
\text{if } P \text{ \{ } X \text { \} else \{ } Y \text{ \}} &= \test(P); X + \test(- P); Y\\
\text{while } P \text{ \{ } X \text{ \}} &= (\test(P);X)^\star;\test(- P)
\end{align*}
Finally, we define the operator $\edn(P)$ which is contains all the
words which end in a state satisfying $P$. Some useful properties of $\edn$ include
\begin{align*}
\edn(P); \test{Q} &\le_\pi \edn(P \cap Q),\\
\test(P) &\le \edn(Q),\\
\text{range}(\Id_P \circ R) \le P \implies \edn(P); \langle R\rangle^\star &\le_\pi \edn(P).
\end{align*}

In the trace model, assignment is defined as
\begin{align*}
  x := e = \bigcup v.\,\test\{\sigma.\,\eval(\sigma,e) = v\} \cdot x \leftarrow v
\end{align*}
where $x \leftarrow v$ denotes the atomic command which assigns the
value $v$ to $x$. The $\eval$ function evaluates an expression $e$ in
the state $\sigma$. Using this definition of assignment we can derive
the assignment rule
\begin{align*}
&\text{unchanged}(\text{vars}(e)) \cap \text{preserves}(P) \cap \text{preserves}(P[x/e]),\\
&\text{unchanged}(- {x})\\
&\vdash \{\edn(P)\} x := e \{\edn(P[x/e])\}.
\end{align*}

The rely condition states that the environment is not allowed to
modify any of the variables used when evaluating $e$, i.e. those
variables must remain unchanged, and also that the environment must
preserve the precondition and postcondition of the assignment
statement. In turn, the assignment statement itself guarantees that it
leaves every variable other than $x$ unchanged. Preserves and unchanged are defined as
\begin{align*}
\text{preserves}(P) &= \langle \{(\sigma,\sigma').\; P(\sigma) \implies P(\sigma')\}\rangle^\star,\\
\text{unchanged}(X) &= \langle \{(\sigma,\sigma').\; \forall v\in X.\; \sigma(v) = \sigma'(v)\}\rangle^\star.
\end{align*}
We also defined two futher rely conditions, increasing and decreasing,
which are defined much like unchanged except they only require that variables
increase or decrease, rather than stay the same.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Example}

Figure \ref{fig:findp} shows the classic FINDP program, which has been
used by numerous authors including Owicki~\cite{owicki},
Jones~\cite{jones}, de Roever~\cite{derover} and
Hayes~\cite{hayes}. The program finds the least element of an array
satisfying the predicate $P$. The index of the first element
satisfying $p$ is placed in the variable $f$. If there are no elements
of the array satisfying $P$ then $f$ will be set to the length of the
array. The program has two subprograms, $A$ and $B$, which run in
parallel, one of which searches the even indices while the other
searches the odd indices. A speedup over a sequential implementation
is acheived as $A$ will terminate when $B$ finds an element of the
array satisfying $P$ which is less than $i_A$.

\begin{figure}
\[
\begin{aligned}
&f_A := \text{len}(\text{array});\\
&f_B := \text{len}(\text{array});\\
&\left(
\begin{aligned}
&i_A = 0\\
&\text{while } i_A < f_A \land i_A < f_B \text{ \{ }\\
&\qquad\text{if } P(\text{array}[i_A]) \text{ \{}\\
&\qquad\qquad f_A := i_A\\
&\qquad\text{\} else \{}\\
&\qquad\qquad i_A := i_A + 2\\
&\qquad\text{\}}\\
&\text{\}}
\end{aligned}
\middle\|
\begin{aligned}
&i_B = 1\\
&\text{while } i_B < f_A \land i_B < f_B \text{ \{}\\
&\qquad\text{if } P(\text{array}[i_B]) \text{ \{}\\
&\qquad\qquad f_B := i_B\\
&\qquad\text{\} else \{}\\
&\qquad\qquad i_B := i_B + 2\\
&\qquad\text{\}}\\
&\text{\}}
\end{aligned}
\right);\\
&f = \text{min}(f_A,f_B)
\end{aligned}
\]
\caption{FINDP Program}
\label{fig:findp}
\end{figure}

To prove the correctness of FINDP, we must show that
\begin{align*}
\text{FINDP} \le_\pi \text{ends}\{\sigma.\; \text{leastp}(\sigma, f)\} + \text{ends}\{\sigma.\; \sigma(f) = \text{len}(\text{array})\}.
\end{align*}
where
\begin{align*}
\text{leastp}(\sigma, x) =  (\forall v<\sigma(x). \lnot P(\sigma(\text{array}[v])))\land P(\sigma(\text{array}[\sigma(x)])).
\end{align*}
The interesting part of this proof is the verification 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

\bibliography{paper}{}
\bibliographystyle{plain}

\end{document}
